{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the CovType dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_EXP = '/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/'\n",
    "PATH_DATA = os.path.join(PATH_TO_EXP, 'data/covtype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `dna` from `libsvm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_zip_train = os.path.join(PATH_DATA, \"dataset_train.bz2\")\n",
    "filename_unzip_train = filename_zip_train.strip('.bz2')\n",
    "filename_raw_train = filename_unzip_train + '.libsvm'\n",
    "\n",
    "if not os.path.exists(filename_zip_train):\n",
    "    !wget -O {filename_zip_train} -t inf \\\n",
    "        https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/covtype.scale01.bz2\n",
    "            \n",
    "!bzip2 -d {filename_zip_train}\n",
    "!mv {filename_unzip_train} {filename_raw_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in `libsvm` input file format, therefore we use `sklearn`'s interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "X_train, y_train = load_svmlight_file(filename_raw_train, dtype=np.float64, query_id=False)\n",
    "\n",
    "X_full = X_train.toarray()\n",
    "\n",
    "classes, sizes = np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data info:\n",
    "* of classes: 7\n",
    "* of data: 581012\n",
    "* of features: 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elem = 1000\n",
    "for n in sizes:\n",
    "    assert n_elem <= n\n",
    "\n",
    "Xs_grouped = []\n",
    "y = []\n",
    "for cls, szs in zip(classes, sizes):\n",
    "    X_group = X_full[y_train == cls]\n",
    "    \n",
    "    idxs = np.arange(0, szs)\n",
    "    rnd_idxs = np.random.permutation(idxs)\n",
    "    \n",
    "    X_group = X_group[idxs][:n_elem]\n",
    "    \n",
    "    for x in X_group:\n",
    "        Xs_grouped.append(x)\n",
    "        y.append(cls)\n",
    "        \n",
    "X = np.array(Xs_grouped)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_objects, n_features = n_elem * len(classes), 54\n",
    "\n",
    "assert n_objects == len(y), \"\"\"Unexpected dimensions.\"\"\"\n",
    "assert (n_objects, n_features) == X.shape, \"\"\"Unexpected dimensions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target dataset for supervised clustering:\n",
    "$$ R_{ij}\n",
    "    = \\begin{cases}\n",
    "        +1 & \\text{ if } y_i = y_j\\,, \\\\\n",
    "        -1 & \\text{ otherwise.}\n",
    "\\end{cases}$$\n",
    "We fill in only the negative class `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:00<00:00, 36346.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "R = np.ones((n_objects, n_objects))\n",
    "for i, yi in enumerate(tqdm.tqdm(y)):\n",
    "    R[i, np.flatnonzero(y != yi)] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row side-features matrix is already in CSR sparse format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "X = coo_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column side-features are an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "\n",
    "Y = dia_matrix((np.ones(n_objects), 0), shape=(n_objects, n_objects))\n",
    "Y = Y.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset into a gzipped pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_staged = os.path.join(PATH_DATA, \"staged_dataset.gz\")\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open(filename_staged, \"wb+\", 4) as fout:\n",
    "    pickle.dump((X, Y, R), fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
