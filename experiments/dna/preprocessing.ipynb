{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the DNA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_EXP = '/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/'\n",
    "PATH_DATA = os.path.join(PATH_TO_EXP, 'data/dna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `dna` from `libsvm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-05 11:38:47--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale\n",
      "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n",
      "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 499248 (488K)\n",
      "Saving to: ‘/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/data/dna/dataset_train.libsvm’\n",
      "\n",
      "100%[======================================>] 499,248      164KB/s   in 3.0s   \n",
      "\n",
      "2018-07-05 11:38:51 (164 KB/s) - ‘/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/data/dna/dataset_train.libsvm’ saved [499248/499248]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_raw_train = os.path.join(PATH_DATA, \"dataset_train.libsvm\")\n",
    "\n",
    "if not os.path.exists(filename_raw_train):\n",
    "    !wget -O {filename_raw_train} -t inf \\\n",
    "        https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-05 11:38:53--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale.t\n",
      "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n",
      "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 293744 (287K) [application/x-troff]\n",
      "Saving to: ‘/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/data/dna/dataset_test.libsvm’\n",
      "\n",
      "100%[======================================>] 293,744     72.0KB/s   in 4.0s   \n",
      "\n",
      "2018-07-05 11:38:58 (72.0 KB/s) - ‘/cobrain/groups/ml_group/experiments/dustpelt/imc_exp/data/dna/dataset_test.libsvm’ saved [293744/293744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_raw_test = os.path.join(PATH_DATA, \"dataset_test.libsvm\")\n",
    "\n",
    "if not os.path.exists(filename_raw_test):\n",
    "    !wget -O {filename_raw_test} -t inf \\\n",
    "        https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale.t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in `libsvm` input file format, therefore we use `sklearn`'s interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "X_train, y_train = load_svmlight_file(filename_raw_train, dtype=np.float64, query_id=False)\n",
    "X_test, y_test = load_svmlight_file(filename_raw_test, dtype=np.float64, query_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "X = vstack([X_train, X_test])\n",
    "y = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data info:\n",
    "* of classes: 3\n",
    "* of data: 2,000 / 1,186 (testing) / 1,400 (tr) / 600 (val)\n",
    "* of features: 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_objects, n_features = 2000 + 1186, 180\n",
    "\n",
    "assert n_objects == len(y), \"\"\"Unexpected dimensions.\"\"\"\n",
    "assert (n_objects, n_features) == X.shape, \"\"\"Unexpected dimensions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target dataset for supervised clustering:\n",
    "$$ R_{ij}\n",
    "    = \\begin{cases}\n",
    "        +1 & \\text{ if } y_i = y_j\\,, \\\\\n",
    "        -1 & \\text{ otherwise.}\n",
    "\\end{cases}$$\n",
    "We fill in only the negative class `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3186/3186 [00:00<00:00, 30397.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "R = np.ones((n_objects, n_objects))\n",
    "for i, yi in enumerate(tqdm.tqdm(y)):\n",
    "    R[i, np.flatnonzero(y != yi)] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row side-features matrix is already in CSR sparse format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3186x180 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 144902 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column side-features are an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "\n",
    "Y = dia_matrix((np.ones(n_objects), 0), shape=(n_objects, n_objects))\n",
    "Y = Y.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset into a gzipped pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_staged = os.path.join(PATH_DATA, \"staged_dataset.gz\")\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open(filename_staged, \"wb+\", 4) as fout:\n",
    "    pickle.dump((X, Y, R), fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
