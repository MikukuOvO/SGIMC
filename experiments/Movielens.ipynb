{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run header.py\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import sample_from_interactions\n",
    "from utils import divide_train_test\n",
    "from utils import from_interactions_to_coo\n",
    "from utils import combine_with_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_path = '/nmnt/x04-hdd/boris_temp/SGIMC_IMC/movielens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"classification\" if False else \"regression\"\n",
    "\n",
    "step_fn = step_qaadmm\n",
    "\n",
    "if PROBLEM == \"classification\":\n",
    "    QAObjectiveLoss = QAObjectiveLogLoss\n",
    "else:\n",
    "    QAObjectiveLoss = QAObjectiveL2Loss  # QAObjectiveHuberLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find out, that problem cannot be solved with only side-information features.\n",
    "\n",
    "X and Y combined with the identity matrices by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions = np.load(exp_path + 'I.npy')\n",
    "X = np.load(exp_path + 'X.npy')\n",
    "Y = np.load(exp_path + 'Y.npy')\n",
    "X = combine_with_identity(X)\n",
    "Y = combine_with_identity(Y)\n",
    "\n",
    "n = len(np.unique(interactions[0])) # users \n",
    "m = len(np.unique(interactions[1])) # items\n",
    "\n",
    "R_full = from_interactions_to_coo(interactions, shape=(n,m))\n",
    "full_mask = R_full.toarray() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGIMC test on Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "Ks = np.arange(2,16,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elements = [0.4, 0.5, 0.6, 0.7, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:17<00:00, 210.79s/it]\n"
     ]
    }
   ],
   "source": [
    "sgimc_losses = []\n",
    "for elem in tqdm(elements):\n",
    "    \n",
    "    Ks_losses = []\n",
    "    for K in Ks:\n",
    "        \n",
    "        random_losses = []\n",
    "        for i in [7,42]:\n",
    "            \n",
    "            interaction_train, interaction_test = sample_from_interactions(interactions, elem, seed=i)\n",
    "            R_train = from_interactions_to_coo(interaction_train, shape=(n,m)).tocsr()\n",
    "            train_mask = R_train.toarray() > 0\n",
    "            test_mask = from_interactions_to_coo(interaction_test, shape=(n,m)).toarray() > 0\n",
    "\n",
    "            problem = IMCProblem(QAObjectiveLoss, X, Y, R_train, n_threads=8)\n",
    "\n",
    "            W_0 = random_state.normal(size=(X.shape[1], K))\n",
    "            H_0 = random_state.normal(size=(Y.shape[1], K))\n",
    "\n",
    "            W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "            W, H = imc_descent(problem, W, H,\n",
    "                               step_fn,                  # the inner optimization\n",
    "                               step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                               n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                               n_init_iterations=0,\n",
    "                               return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                               rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                               atol=1e-7,                # absolute tolerance\n",
    "                               verbose=False,            # show the progress bar\n",
    "                               check_product=True,       # use the product W H' for stopping\n",
    "                               )\n",
    "            \n",
    "            R_hat = get_prediction(X, W, H, Y)\n",
    "            random_losses.append(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "            \n",
    "        Ks_losses.append(np.mean(random_losses))\n",
    "    sgimc_losses.append(np.min(Ks_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgimc_losses = np.array(sgimc_losses)\n",
    "np.save(exp_path + 'sgimc_random.npy', sgimc_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold-start sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elements = [0.7, 0.75, 0.8, 0.85, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "100%|██████████| 5/5 [52:35<00:00, 632.98s/it]\n"
     ]
    }
   ],
   "source": [
    "sgimc_losses = []\n",
    "for elem in tqdm(elements):\n",
    "    \n",
    "    Ks_losses = []\n",
    "    for K in Ks:\n",
    "        \n",
    "        random_losses = []\n",
    "        for i in [7,42]:\n",
    "            \n",
    "            I_oo, I_on, I_no, I_nn = divide_train_test(interactions, shape=(n,m), train_size=elem, seed=i)\n",
    "            R_oo = from_interactions_to_coo(I_oo, shape=(n,m)).tocsr()\n",
    "            mask_no = from_interactions_to_coo(I_no, shape=(n,m)).toarray() > 0\n",
    "\n",
    "            problem = IMCProblem(QAObjectiveLoss, X, Y, R_oo, n_threads=8)\n",
    "\n",
    "            W_0 = random_state.normal(size=(X.shape[1], K))\n",
    "            H_0 = random_state.normal(size=(Y.shape[1], K))\n",
    "\n",
    "            W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "            W, H = imc_descent(problem, W, H,\n",
    "                               step_fn,                  # the inner optimization\n",
    "                               step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                               n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                               n_init_iterations=0,\n",
    "                               return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                               rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                               atol=1e-7,                # absolute tolerance\n",
    "                               verbose=False,            # show the progress bar\n",
    "                               check_product=True,       # use the product W H' for stopping\n",
    "                               )\n",
    "            \n",
    "            R_hat = get_prediction(X, W, H, Y)\n",
    "            random_losses.append(relative_loss(R_full.toarray(), R_hat, mask=mask_no))\n",
    "            \n",
    "        Ks_losses.append(np.mean(random_losses))\n",
    "    sgimc_losses.append(np.min(Ks_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgimc_losses = np.array(sgimc_losses)\n",
    "np.save(exp_path + 'sgimc_coldstart.npy', sgimc_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elem_random = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "elem_coldstart = [0.7, 0.75, 0.8, 0.85, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.5, 0.6, 0.7, 0.8]\n",
      "[0.17741381 0.16399969 0.1302093  0.09347925 0.08855051]\n",
      "[0.08179756 0.08246713 0.07103076 0.06488327 0.06230304]\n",
      "[0.49912426 0.40738828 0.25007069 0.06655666 0.06541152]\n"
     ]
    }
   ],
   "source": [
    "sgimc_random = np.load(exp_path + 'sgimc_random.npy')\n",
    "imc_random = np.load(exp_path + 'imc_random.npy')\n",
    "mf_random = np.load(exp_path + 'mf_random.npy')\n",
    "\n",
    "print(elem_random)\n",
    "print(sgimc_random)\n",
    "print(imc_random)\n",
    "print(mf_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6102101415713154,\n",
       " 0.4639162882313005,\n",
       " 0.29762718190317433,\n",
       " 0.26213268239100085,\n",
       " 0.11268782604736596]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgimc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.75, 0.8, 0.85, 0.9]\n",
      "[0.16530622 0.14961579 0.20616977 0.14622519 0.18784847]\n",
      "[0.09620888 0.09391305 0.09666226 0.09177917 0.08917045]\n",
      "[0.99920574 0.99668088 0.99550499 0.99544602 0.99067397]\n"
     ]
    }
   ],
   "source": [
    "sgimc_coldstart = np.load(exp_path + 'sgimc_coldstart.npy')\n",
    "imc_coldstart = np.load(exp_path + 'imc_coldstart.npy')\n",
    "mf_coldstart = np.load(exp_path + 'mf_coldstart.npy')\n",
    "\n",
    "print(elem_coldstart)\n",
    "print(sgimc_coldstart)\n",
    "print(imc_coldstart)\n",
    "print(mf_coldstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
