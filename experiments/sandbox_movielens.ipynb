{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run header.py\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import sample_from_interactions\n",
    "from utils import from_interactions_to_coo\n",
    "from utils import combine_with_identity\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_path = '/nmnt/x04-hdd/boris_temp/SGIMC_IMC/movielens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"classification\" if False else \"regression\"\n",
    "\n",
    "step_fn = step_qaadmm\n",
    "\n",
    "if PROBLEM == \"classification\":\n",
    "    QAObjectiveLoss = QAObjectiveLogLoss\n",
    "else:\n",
    "    QAObjectiveLoss = QAObjectiveL2Loss  # QAObjectiveHuberLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions = np.load(exp_path + 'I.npy')\n",
    "X = np.load(exp_path + 'X.npy')\n",
    "Y = np.load(exp_path + 'Y.npy')\n",
    "\n",
    "n = len(np.unique(interactions[0])) # users \n",
    "m = len(np.unique(interactions[1])) # items\n",
    "\n",
    "\n",
    "X_comb = combine_with_identity(X)\n",
    "Y_comb = combine_with_identity(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_train_test(I, X, Y, shape, q, seed=42):\n",
    "    # TODO: add q1 and q2 instead q\n",
    "    n, m = shape\n",
    "    user_ids = np.array([i for i in range(n)])\n",
    "    item_ids = np.array([i for i in range(m)])\n",
    "    \n",
    "    train_user_ids, test_user_ids = TTS(user_ids, train_size=q, random_state=seed, shuffle=False)\n",
    "    train_item_ids, test_item_ids = TTS(item_ids, train_size=q, random_state=seed, shuffle=False)\n",
    "    \n",
    "    train_train, train_test, test_train, test_test = [], [], [], []\n",
    "    for elem in tqdm(I.T):\n",
    "        if elem[0] in train_user_ids and elem[1] in train_item_ids:\n",
    "            train_train.append(elem)\n",
    "        elif elem[0] in train_user_ids and elem[1] in test_item_ids:\n",
    "            train_test.append(elem)\n",
    "        elif elem[0] in test_user_ids and elem[1] in train_item_ids:\n",
    "            test_train.append(elem)\n",
    "        else:\n",
    "            test_test.append(elem)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 196,  242,    3],\n",
       "       [ 186,  302,    3],\n",
       "       [  22,  377,    1],\n",
       "       ...,\n",
       "       [ 276, 1090,    1],\n",
       "       [  13,  225,    2],\n",
       "       [  12,  203,    3]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_full = from_interactions_to_coo(interactions)\n",
    "full_mask = R_full.toarray() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_elem = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.48it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10411037852965176\n",
      "0.09156078318939746\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## n_elem = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 12.74it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10402310376532233\n",
      "0.07513154157350502\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_elem = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-5\n",
    "C_group = 2e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 7e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 12.94it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15825099880872626\n",
      "0.0750629258120321\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## n_elem = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 14.32it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2561068724565415\n",
      "0.08070438832332932\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
