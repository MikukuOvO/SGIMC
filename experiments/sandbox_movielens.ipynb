{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run header.py\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import sample_from_interactions\n",
    "from utils import from_interactions_to_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_path = '/nmnt/x04-hdd/boris_temp/SGIMC_IMC/movielens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"classification\" if False else \"regression\"\n",
    "\n",
    "step_fn = step_qaadmm\n",
    "\n",
    "if PROBLEM == \"classification\":\n",
    "    QAObjectiveLoss = QAObjectiveLogLoss\n",
    "else:\n",
    "    QAObjectiveLoss = QAObjectiveL2Loss  # QAObjectiveHuberLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 2e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 1e1\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-5,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-8,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions = np.load(exp_path + 'I.npy')\n",
    "X = np.load(exp_path + 'X.npy')\n",
    "Y = np.load(exp_path + 'Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_full = from_interactions_to_coo(interactions)\n",
    "full_mask = R_full.toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = from_interactions_to_coo(interaction_train).tocsr()\n",
    "test_mask = from_interactions_to_coo(interaction_test).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 23)\n",
      "(1682, 20)\n",
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(R_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel died :(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X, Y, R_train, n_threads=4)\n",
    "\n",
    "W_0 = random_state.normal(size=(X.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if PROBLEM == \"classification\":\n",
    "    C = 1e0, 1e-1, 1e-3\n",
    "    eta = 1e0\n",
    "else:\n",
    "    # C = 2e-5, 2e-3, 0\n",
    "    C = 2e-3, 2e-4, 1e-4\n",
    "    eta = 1e1\n",
    "    \n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-5,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-8,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_samples, n_objects = 800, 1600\n",
    "n_rank = 25\n",
    "\n",
    "scale = 0.05\n",
    "noise = 0.10\n",
    "\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, W_ideal, Y, H_ideal, R_noisy_full, R_clean_full = make_imc_data(\n",
    "        n_samples, 50, n_objects, 50,\n",
    "        n_rank, scale=(scale, scale), noise=scale*noise,\n",
    "        binarize=(PROBLEM == \"classification\"),\n",
    "        random_state=random_state,\n",
    "        return_noisy_only=False)\n",
    "\n",
    "R_train, mask = sparsify(R_noisy_full, 0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.82it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X, Y, R_train, n_threads=8)\n",
    "    \n",
    "        \n",
    "W_0 = random_state.normal(size=(X.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
