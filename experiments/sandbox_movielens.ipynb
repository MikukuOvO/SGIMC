{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run header.py\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import sample_from_interactions\n",
    "from utils import from_interactions_to_coo\n",
    "from utils import combine_with_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_path = '/nmnt/x04-hdd/boris_temp/SGIMC_IMC/movielens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"classification\" if False else \"regression\"\n",
    "\n",
    "step_fn = step_qaadmm\n",
    "\n",
    "if PROBLEM == \"classification\":\n",
    "    QAObjectiveLoss = QAObjectiveLogLoss\n",
    "else:\n",
    "    QAObjectiveLoss = QAObjectiveL2Loss  # QAObjectiveHuberLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions = np.load(exp_path + 'I.npy')\n",
    "X = np.load(exp_path + 'X.npy')\n",
    "Y = np.load(exp_path + 'Y.npy')\n",
    "\n",
    "X_comb = combine_with_identity(X)\n",
    "Y_comb = combine_with_identity(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_full = from_interactions_to_coo(interactions)\n",
    "full_mask = R_full.toarray() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_elem = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 20\n",
    "\n",
    "n_elem = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1097722307428194\n",
      "0.07387231049226703\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## n_elem = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-4\n",
    "C_group = 3e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 5e0\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.79it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09976071819206714\n",
      "0.07592997966454759\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_elem = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_ridge = 1e-5\n",
    "C_group = 2e-4\n",
    "C_lasso = 10 * C_group\n",
    "C = (C_lasso, C_group, C_ridge)\n",
    "\n",
    "eta = 1e1\n",
    "\n",
    "step_kwargs = {\n",
    "    \"C\": C,                 # the regularizr constants (C_lasso, C_group, C_ridge)\n",
    "    \"eta\": eta,             # the eta of the ADMM (larger - faster but more unstable)\n",
    "    \"rtol\": 1e-4,           # the relative tolerance for stopping the ADMM\n",
    "    \"atol\": 1e-7,           # the absolute tolerance\n",
    "    \"method\": \"cg\",         # the method to use in Sub_0\n",
    "    \"n_iterations\": 2,      # the number of iterations of the inner ADMM\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "K = 10\n",
    "\n",
    "n_elem = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/boris/env3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "interaction_train, interaction_test = sample_from_interactions(interactions, n_elem)\n",
    "\n",
    "R_train = from_interactions_to_coo(interaction_train, R_shape=R_full.shape).tocsr()\n",
    "train_mask = R_train.toarray() > 0\n",
    "test_mask = from_interactions_to_coo(interaction_test, R_shape=R_full.shape).toarray() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.28it/s]\n"
     ]
    }
   ],
   "source": [
    "problem = IMCProblem(QAObjectiveLoss, X_comb, Y_comb, R_train, n_threads=8)\n",
    "\n",
    "W_0 = random_state.normal(size=(X_comb.shape[1], K))\n",
    "H_0 = random_state.normal(size=(Y_comb.shape[1], K))\n",
    "\n",
    "W, H = W_0.copy(), H_0.copy()\n",
    "\n",
    "W, H = imc_descent(problem, W, H,\n",
    "                   step_fn,                  # the inner optimization\n",
    "                   step_kwargs=step_kwargs,  # asrtguments for the inner optimizer\n",
    "                   n_iterations=n_iter,      # the number of outer iterations (Gauss-Siedel)\n",
    "                   n_init_iterations=0,\n",
    "                   return_history=True,      # Record the evolution of the matrices (W, H)\n",
    "                   rtol=1e-5,                # relative stopping tolerance for the outer iterations\n",
    "                   atol=1e-7,                # absolute tolerance\n",
    "                   verbose=True,             # show the progress bar\n",
    "                   check_product=True,       # use the product W H' for stopping\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15727194503168554\n",
      "0.08519146724899301\n"
     ]
    }
   ],
   "source": [
    "R_hat = get_prediction(X_comb, W, H, Y_comb)\n",
    "\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=test_mask))\n",
    "print(relative_loss(R_full.toarray(), R_hat, mask=train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
